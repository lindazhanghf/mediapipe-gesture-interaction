<!DOCTYPE html>
<html>

<head>
    <!-- <meta http-equiv="refresh" content="0;url=dist/index.html"> -->
    <meta charset="utf-8"/>
    <title>Hand Tracking Web</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

</head>

<body>
  <script language="javascript">
    const VIDEO_WIDTH = 640;
    const VIDEO_HEIGHT = 500;

    let websocket;
    if ("WebSocket" in window) {
      //  open a web socket
      websocket = new WebSocket("ws://localhost:4649/Echo");

      websocket.onopen = function() {
        
        // Web Socket is connected, send data using send()
        websocket.send("Connected to WebSocket server.");
        console.log("Message is sent: 'Connected to WebSocket server'");
      };

      websocket.onmessage = function (evt) { 
        var received_msg = evt.data;
        console.log("Message is received: " + received_msg);
      };

      websocket.onclose = function() { 
        // websocket is closed.
        console.log("Connection is closed."); 
      };
    } else {
        // The browser doesn't support WebSocket
        alert("WebSocket NOT supported by your Browser!");
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */

    async function main() {
      // Load the MediaPipe handpose model.
      var model = await handpose.load();

      // Pass in a video stream (or an image, canvas, or 3D tensor) to obtain a
      // hand prediction from the MediaPipe graph.
      const video = await setupCamera();
      video.play();

      async function hand_tracking() {
        const predictions = await model.estimateHands(video)
        if (predictions.length > 0) {
          const result = predictions[0].landmarks
          // console.log(result)
        }
        return predictions
      }
      
      setInterval(async function() {
        hand_tracking().then((prediction) => {
          if (prediction.length) {
            console.log(prediction[0])
            websocket.send(JSON.stringify(prediction[0]));
          }
        })
      }, 33) // ~ 30 FPS
    }

    async function setupCamera() {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error(
          'Browser API navigator.mediaDevices.getUserMedia not available');
      }

      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({
        'audio': false,
        'video': {
          facingMode: 'user',
          // Only setting the video to a specified size in order to accommodate a
          // point cloud, so on mobile devices accept the default size.
          width: VIDEO_WIDTH,
          height: VIDEO_HEIGHT,
        },
      });
      video.srcObject = stream;

      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          resolve(video);
        };
      });
    }

    main();
  </script>
  <div>
    hand tracking
  </div>

  <div>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>
  </div>
</body>

</html>